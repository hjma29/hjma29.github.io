{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"whitepaper/","title":"Monitoring HPE GreenLake Servers running GPU using Grafana and Prometheus","text":""},{"location":"whitepaper/#overview","title":"Overview","text":"<p>HPE GreenLake provides a cloud-native platform for managing and monitoring infrastructure with built-in tools and dashboards. While GreenLake offers comprehensive native monitoring capabilities, organizations can also leverage the GreenLake API to integrate with popular open-source tools like Grafana and Prometheus. This approach enables teams to consolidate monitoring data across hybrid environments, utilize existing observability workflows, and create customized dashboards tailored to specific operational needs.</p>"},{"location":"whitepaper/#kubernetes-and-helm-setup","title":"Kubernetes and Helm Setup","text":""},{"location":"whitepaper/#environment-verification","title":"Environment Verification","text":"<p>Before proceeding with the monitoring setup, verify that your Kubernetes cluster has the necessary components installed. The following shows a working environment with the GPU Operator and Prometheus monitoring stack deployed:</p> <p>Services running in the gpu-operator namespace: - <code>gpu-operator</code>: Core service for GPU management (ClusterIP: 10.233.44.80:8080) - <code>nvidia-dcgm-exporter</code>: DCGM metrics exporter for Prometheus integration (ClusterIP: 10.233.15.59:9400)</p> <p>Helm releases: - <code>gpu-operator-1753140595</code> (v25.3.2) in the <code>gpu-operator</code> namespace - <code>kube-prometheus-stack</code> (76.3.0) in the <code>monitoring</code> namespace</p> <p>You can verify your setup using the following commands:</p> <pre><code>wsl=&gt; k get svc -n gpu-operator \nNAME                   TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE\ngpu-operator           ClusterIP   10.233.44.80   &lt;none&gt;        8080/TCP   78d\nnvidia-dcgm-exporter   ClusterIP   10.233.15.59   &lt;none&gt;        9400/TCP   78d\n\nwsl=&gt; helm list -A\nNAME                    NAMESPACE       REVISION        UPDATED                                 STATUS          CHART                           APP VERSION\ngpu-operator-1753140595 gpu-operator    4               2025-08-14 19:20:42.329819669 -0700 MST deployed        gpu-operator-v25.3.2            v25.3.2    \nkube-prometheus-stack   monitoring      5               2025-08-15 13:06:31.169338089 -0700 MST deployed        kube-prometheus-stack-76.3.0    v0.84.1    \nhjma@HSTHJMA02:~\n</code></pre>"},{"location":"whitepaper/#external-access-configuration","title":"External Access Configuration","text":"<p>The cluster has been configured with NodePort services to enable external access to Grafana and Prometheus: <pre><code>wsl=&gt; k get svc --field-selector spec.type=NodePort\nNAME                               TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)                         AGE\nkube-prometheus-stack-grafana      NodePort   10.233.22.241   &lt;none&gt;        80:30080/TCP                    55d\nkube-prometheus-stack-prometheus   NodePort   10.233.8.106    &lt;none&gt;        9090:30090/TCP,8080:30398/TCP   55d\n</code></pre></p>"},{"location":"whitepaper/#gpu-utilization-simulation","title":"GPU utilization simulation","text":"<p>To simulate GPU load and verify monitoring functionality, we deployed a test pod running the gpu-burn utility. This tool performs intensive GPU computations, allowing us to observe GPU utilization metrics in our monitoring dashboards.</p> <p>The following YAML manifest creates a pod that clones the gpu-burn repository, compiles it, and runs continuous GPU stress testing:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n    name: gpu-burn\nspec:\n    containers:\n        - name: gpu-burn\n            image: nvidia/cuda:12.2.0-devel-ubuntu22.04 \n            command: [\"/bin/bash\", \"-c\"]\n            args:\n                - |\n                    apt update &amp;&amp; apt install -y git build-essential &amp;&amp; \\\n                    git clone https://github.com/wilicc/gpu-burn.git &amp;&amp; \\\n                    cd gpu-burn &amp;&amp; make &amp;&amp; ./gpu_burn 999999 \n            resources:\n                limits:\n                    nvidia.com/gpu: 1\n    restartPolicy: Never\n</code></pre> <p>Key configuration details: - Base image: <code>nvidia/cuda:12.2.0-devel-ubuntu22.04</code> provides the CUDA development environment - GPU allocation: <code>nvidia.com/gpu: 1</code> requests a single GPU from the cluster - Runtime: <code>gpu_burn 999999</code> runs for approximately 277 hours (effectively continuous) - Restart policy: <code>Never</code> ensures the pod completes its run without automatic restarts</p> <p>Deploy the pod using: <pre><code>kubectl apply -f gpu-burn.yaml\n</code></pre></p>"}]}