{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Home</p>"},{"location":"whitepaper/","title":"NVIDIA GPU Operator Setup with Grafana and Prometheus","text":""},{"location":"whitepaper/#overview","title":"Overview","text":"<p>Currently, two Kubernetes clusters are deployed: <code>p1</code> running Prometheus and <code>c2</code> running NVIDIA GPU Operator. Long-term, these may be consolidated into a single cluster for simplicity.</p>"},{"location":"whitepaper/#cluster-configuration","title":"Cluster Configuration","text":"<p>Two Kubernetes clusters are running:</p> <ul> <li>P1 cluster: Runs Grafana and Prometheus in the <code>monitoring</code> namespace</li> <li>P2 cluster: Has Grafana-Prometheus in the <code>monitoring</code> namespace</li> </ul> <p>The P1 cluster runs Grafana/Prometheus with the main prometheus-grafana service set up as NodePort on port 31600. Launch a web browser to <code>p1-worker-vm:31600</code>; the default login is <code>admin/prom-operator</code>.</p>"},{"location":"whitepaper/#p1-cluster-details","title":"P1 Cluster Details","text":"<pre><code>wsl=&gt; k config current-context\np1-admin@p1.grafana\n\nwsl=&gt; k get node\nNAME                                STATUS   ROLES           AGE   VERSION\np1-master-vm.hst.enablement.local   Ready    control-plane   79d   v1.33.1\np1-worker-vm.hst.enablement.local   Ready    &lt;none&gt;          79d   v1.33.1\nhjma@HSTHJMA02:~\n\n\nwsl=&gt; k get svc -n monitoring\nNAME                                       TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE\nalertmanager-operated                      ClusterIP   None             &lt;none&gt;        9093/TCP,9094/TCP,9094/UDP   54d\nprometheus-operated                        ClusterIP   None             &lt;none&gt;        9090/TCP                     54d\ntest-prometheus-grafana                    NodePort    10.97.92.135     &lt;none&gt;        80:31600/TCP                 54d\ntest-prometheus-kube-prome-alertmanager    ClusterIP   10.100.1.114     &lt;none&gt;        9093/TCP,8080/TCP            54d\ntest-prometheus-kube-prome-operator        ClusterIP   10.100.184.136   &lt;none&gt;        443/TCP                      54d\ntest-prometheus-kube-prome-prometheus      ClusterIP   10.107.215.146   &lt;none&gt;        9090/TCP,8080/TCP            54d\ntest-prometheus-kube-state-metrics         ClusterIP   10.101.113.18    &lt;none&gt;        8080/TCP                     54d\ntest-prometheus-prometheus-node-exporter   ClusterIP   10.100.132.103   &lt;none&gt;        9100/TCP                     54d\n\nwsl=&gt; curl 10.16.160.42:31600\n&lt;a href=\"/login\"&gt;Found&lt;/a&gt;.\n</code></pre>"},{"location":"whitepaper/#prometheus-helm-configuration","title":"Prometheus Helm Configuration","text":"<p>In the P1 cluster, Grafana/Prometheus was set up using Helm:</p> <pre><code>wsl=&gt; helm list -A --filter 'prometheus'\nNAME            NAMESPACE       REVISION        UPDATED                                 STATUS    CHART                            APP VERSION\ntest-prometheus monitoring      3               2025-07-22 17:11:52.125453 -0700 MST    deployed  kube-prometheus-stack-75.4.0     v0.83.0\nhjma@HSTHJMA02:~\n\nwsl=&gt; helm -n monitoring get values test-prometheus --revision 3\nUSER-SUPPLIED VALUES:\nprometheus:\n  prometheusSpec:\n    additionalScrapeConfigs:\n    - job_name: c2-dcgm-exporter\n      static_configs:\n      - targets:\n        - 10.16.160.54:30639\n        - 10.16.160.54:30639\nhjma@HSTHJMA02:~\nwsl=&gt; helm -n monitoring get values test-prometheus --revision 2\nUSER-SUPPLIED VALUES:\nprometheus:\n  prometheusSpec:\n    additionalScrapeConfigs:\n    - job_name: c2-dcgm-exporter\n      static_configs:\n      - targets:\n        - 10.16.160.54:31065\n        - 10.16.160.55:31065\nhjma@HSTHJMA02:~\nwsl=&gt; helm -n monitoring get values test-prometheus --revision 1\nUSER-SUPPLIED VALUES:\nnull\nhjma@HSTHJMA02:~\n</code></pre>"},{"location":"whitepaper/#c2-cluster-configuration","title":"C2 Cluster Configuration","text":"<p>The C2 cluster has the GPU Operator in the <code>gpu-operator</code> namespace.</p>"},{"location":"whitepaper/#dcgm-exporter-overview","title":"DCGM Exporter Overview","text":"<p>The NVIDIA GPU Operator Helm chart deploys a DCGM (Data Center GPU Manager) exporter by default, but there are important nuances:</p> <ul> <li>The DCGM exporter Pod will be created automatically when the operator detects a node with an NVIDIA GPU and the dcgm-exporter component is enabled in its values.</li> <li>In the stock gpu-operator Helm chart from NVIDIA's repo, the DCGM exporter is enabled by default (<code>dcgmExporter.enabled: true</code>).</li> </ul> <p>However:</p> <ol> <li>ServiceMonitor is not enabled by default.</li> <li>This means Prometheus won't automatically scrape the DCGM exporter unless you either:<ul> <li>Enable the ServiceMonitor (<code>dcgmExporter.serviceMonitor.enabled: true</code>), or</li> <li>Manually define a scrape config in Prometheus.</li> </ul> </li> <li>No GPUs \u2192 No exporter pods</li> <li>If the GPU Operator is installed into a cluster without GPU-capable nodes, the DaemonSet for dcgm-exporter may not schedule any pods.</li> </ol>"},{"location":"whitepaper/#servicemonitor-overview","title":"ServiceMonitor Overview","text":"<p>A ServiceMonitor is not a built-in Kubernetes object like a Pod, Deployment, or Service. It's a Custom Resource Definition (CRD) that comes from the Prometheus Operator (or kube-prometheus-stack Helm chart).</p> <p>How it works:</p> <ul> <li>You first deploy Prometheus Operator (usually via kube-prometheus-stack Helm chart).</li> <li>The Prometheus Operator introduces new CRDs, including:</li> <li>ServiceMonitor</li> <li>PodMonitor</li> <li>PrometheusRule</li> <li>Prometheus Operator watches for ServiceMonitor objects and dynamically updates Prometheus' scrape configuration to match them.</li> </ul> <p>For NVIDIA GPU Operator:</p> <ul> <li>If set to true, it will create a ServiceMonitor for the DCGM exporter so Prometheus can scrape GPU metrics automatically.</li> <li>If you don't have Prometheus Operator installed, creating a ServiceMonitor will do nothing\u2014because only the Prometheus Operator knows how to use it.</li> </ul>"},{"location":"whitepaper/#c2-cluster-details","title":"C2 Cluster Details","text":"<p>The DCGM exporter typically uses port <code>9400</code>.</p> <pre><code>wsl=&gt; k config use-context c2-admin@c2.gpu\nSwitched to context \"c2-admin@c2.gpu\".\nhjma@HSTHJMA02:~\n\n\nwsl=&gt; k get svc -n gpu-operator\nNAME                   TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE\ngpu-operator           ClusterIP   10.233.44.80   &lt;none&gt;        8080/TCP   23d\nnvidia-dcgm-exporter   ClusterIP   10.233.15.59   &lt;none&gt;        9400/TCP   23d\nhjma@HSTHJMA02:\n\n\nwsl=&gt; helm list -A\nNAME                    NAMESPACE       REVISION        UPDATED                                 STATUS          CHART                   APP VERSION\ngpu-operator-1753140595 gpu-operator    1               2025-07-21 16:30:01.929686717 -0700 MST deployed        gpu-operator-v25.3.0    v25.3.0\nwsl=&gt; helm show values nvidia/gpu-operator | grep -A20 dcgmExporter:\ndcgmExporter:\n  enabled: true\n  repository: nvcr.io/nvidia/k8s\n  image: dcgm-exporter\n  version: 4.2.3-4.1.3-ubuntu22.04\n  imagePullPolicy: IfNotPresent\n  env:\n    - name: DCGM_EXPORTER_LISTEN\n      value: \":9400\"\n    - name: DCGM_EXPORTER_KUBERNETES\n      value: \"true\"\n    - name: DCGM_EXPORTER_COLLECTORS\n      value: \"/etc/dcgm-exporter/dcp-metrics-included.csv\"\n  resources: {}\n  service:\n    internalTrafficPolicy: Cluster\n  serviceMonitor:\n    enabled: false\n    interval: 15s\n    honorLabels: false\n    additionalLabels: {}\n</code></pre>"},{"location":"whitepaper/#making-c2-dcgm-exporter-service-available-to-p1-prometheus","title":"Making C2 DCGM Exporter Service Available to P1 Prometheus","text":"<p>We can change the <code>dcgm-exporter</code> service from the default <code>ClusterIP</code> to <code>NodePort</code>. If we patch Kubernetes using <code>kubectl</code>, the change will not be persistent, as Helm values remain at their defaults. The next time you upgrade the gpu-operator Helm chart, the service will revert to ClusterIP. We need to modify Helm values to make the change persistent.</p> <p>[!NOTE] After hours of investigation, Helm does not have a value to lock the NodePort port number. It can only define the type as NodePort and the <code>internalTrafficPolicy</code> field. Attempting to define NodePort 39400 to lock the port (preventing changes after restart or chart upgrade) resulted in \"field not supported\" errors. This limitation led to the decision to install Prometheus on the C2 cluster to avoid this complexity.</p> <p>[!TIP] This is a useful tip or suggestion.</p> <p>[!IMPORTANT] This is important information that users should not miss.</p> <p>[!WARNING] This is a warning about a potential issue or a caution.</p> <p>Custom Title</p> <p>Content here</p> Collapsible Note <p>Click to expand</p> <p>Watch Out!</p> <p>Important warning</p> <p>Note: this is a note to see how github render compare with MKDocs. this line has two trailing spaces. test second line this is 3rd line disable hl2</p>"}]}