{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"whitepaper/","title":"Home","text":""},{"location":"whitepaper/#monitoring-hpe-greenlake-servers-running-gpus-using-grafana-and-prometheus","title":"Monitoring HPE GreenLake Servers Running GPUs Using Grafana and Prometheus","text":""},{"location":"whitepaper/#overview","title":"Overview","text":"<p>HPE GreenLake Compute Ops Management provides a cloud-native platform for managing and monitoring compute infrastructure with built-in tools and dashboards. While Compute Ops Management offers comprehensive native monitoring capabilities, organizations can also leverage the Compute Ops Management REST API to integrate with popular open-source tools like Grafana and Prometheus. This approach enables teams to consolidate monitoring data across hybrid environments, utilize existing observability workflows, and create customized dashboards tailored to specific operational needs\u2014particularly for GPU-accelerated workloads running on HPE servers.</p>"},{"location":"whitepaper/#benefits-of-grafana-cloud-integration","title":"Benefits of Grafana Cloud Integration","text":"<p>Grafana Cloud provides a centralized monitoring platform that bridges both public cloud APIs and private infrastructure metrics, offering several key advantages:</p>"},{"location":"whitepaper/#unified-observability-across-hybrid-environments","title":"Unified Observability Across Hybrid Environments","text":"<ul> <li> <p>HPE GreenLake API Integration: Using the Infinity data source plugin, Grafana Cloud can directly query HPE GreenLake Compute Ops Management REST APIs to retrieve server health, firmware status, and hardware telemetry data from your public cloud-managed infrastructure</p> </li> <li> <p>Internal Metrics Aggregation: Simultaneously receives GPU utilization, Kubernetes cluster metrics, and application performance data from your on-premises Prometheus instances via remote write protocol</p> </li> <li> <p>Single Pane of Glass: Consolidates metrics from both HPE GreenLake-managed servers and local GPU workloads into unified dashboards</p> </li> </ul>"},{"location":"whitepaper/#api-accessing-hpe-greenlake-compute-ops-management","title":"API Accessing HPE GreenLake Compute Ops Management","text":"<p>In order for Grafana Cloud to access HPE GreenLake Compute Ops Management, we need to first create client API user and obtain user secret. For details, please see HPE GreenLake access token instructions</p> <p>The following screen shows the \"Personal API endpoints\" creation in the workspace dashboard.</p> <p></p> <p>You need to note down the client ID and secret so you can configure Grafana later using this information.</p> <p></p>"},{"location":"whitepaper/#infinity-data-source","title":"Infinity Data Source","text":"<p>The Grafana Infinity data source enables direct integration with HPE GreenLake REST APIs, allowing users to query and visualize data from any HTTP/REST endpoint without requiring custom backend development. Originally a community-driven plugin, Infinity was officially adopted by Grafana Labs and is now maintained as part of the core Grafana ecosystem. This transition ensures long-term support, regular updates, and better integration with Grafana's authentication frameworks.</p> <p>Key capabilities include: - REST API integration - Query HPE GreenLake Compute Ops Management APIs directly from Grafana - OAuth2 authentication - Native support for token-based authentication flows - Data transformation - Parse JSON responses and transform them into visualization-ready formats</p> <p>This Infinity plugin supports automatic token refresh when accessing HPE GreenLake Compute Ops Management. The implementation leverages Go's built-in <code>golang.org/x/oauth2</code> library, which automatically handles token refresh logic when the access token expires. The OAuth2 token source automatically refreshes the access token using the refresh token before making API requests, ensuring uninterrupted authentication without manual intervention.</p> <p>The configuration of the Infinity data source is shown below. Users need to provide the HPE GreenLake API Client ID/Secret and also allow access to the API endpoints.</p> <p></p>"},{"location":"whitepaper/#grafana-cloud-dashboard","title":"Grafana Cloud Dashboard","text":"<p>With the Infinity data source successfully configured, users can configure the dashboard to query information following the HPE Compute Ops Management API Guide</p> <p></p>"},{"location":"whitepaper/#kubernetes-and-helm-setup","title":"Kubernetes and Helm Setup","text":""},{"location":"whitepaper/#kubernetes-cluster-setup","title":"Kubernetes cluster setup","text":"<p>This demonstration environment utilizes a high-availability Kubernetes cluster consisting of three control plane nodes and two worker nodes.</p> <pre><code>wsl=&gt; k get node -o wide\nNAME                                STATUS   ROLES           AGE   VERSION   INTERNAL-IP    EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION       CONTAINER-RUNTIME\nc2-cp-01.hst.enablement.local       Ready    control-plane   80d   v1.32.5   10.16.160.51   &lt;none&gt;        Ubuntu 22.04.5 LTS   5.15.0-144-generic   containerd://2.0.5\nc2-cp-02.hst.enablement.local       Ready    control-plane   80d   v1.32.5   10.16.160.52   &lt;none&gt;        Ubuntu 22.04.5 LTS   5.15.0-144-generic   containerd://2.0.5\nc2-cp-03.hst.enablement.local       Ready    control-plane   80d   v1.32.5   10.16.160.53   &lt;none&gt;        Ubuntu 22.04.5 LTS   5.15.0-144-generic   containerd://2.0.5\nc2-worker-01.hst.enablement.local   Ready    &lt;none&gt;          80d   v1.32.5   10.16.160.54   &lt;none&gt;        Ubuntu 22.04.5 LTS   5.15.0-144-generic   containerd://2.0.5\nc2-worker-02.hst.enablement.local   Ready    &lt;none&gt;          80d   v1.32.5   10.16.160.55   &lt;none&gt;        Ubuntu 22.04.5 LTS   5.15.0-144-generic   containerd://2.0.5\n</code></pre>"},{"location":"whitepaper/#kubernetes-namespace-setup","title":"Kubernetes namespace setup","text":"<p>The cluster is equipped with the <code>gpu-operator</code> namespace for NVIDIA GPU management and the <code>monitoring</code> namespace hosting the Prometheus stack, with external access enabled via NodePort services. </p><pre><code>wsl=&gt; kubectl get ns | grep -vE '^(kube-|default)'\nNAME              STATUS   AGE\ngpu-operator      Active   80d\nmonitoring        Active   56d\n\nwsl=&gt; k get svc -n gpu-operator \nNAME                   TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE\ngpu-operator           ClusterIP   10.233.44.80   &lt;none&gt;        8080/TCP   78d\nnvidia-dcgm-exporter   ClusterIP   10.233.15.59   &lt;none&gt;        9400/TCP   78d\n\nwsl=&gt; k get svc --field-selector spec.type=NodePort -n monitoring\nNAME                               TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)                         AGE\nkube-prometheus-stack-grafana      NodePort   10.233.22.241   &lt;none&gt;        80:30080/TCP                    56d\nkube-prometheus-stack-prometheus   NodePort   10.233.8.106    &lt;none&gt;        9090:30090/TCP,8080:30398/TCP   56d\n</code></pre><p></p>"},{"location":"whitepaper/#helm-chart-installation","title":"Helm chart installation","text":"<p>The environment uses Helm to manage two key components: the NVIDIA GPU Operator for GPU resource management and the Kube Prometheus Stack for monitoring and observability.</p> <pre><code>wsl=&gt; helm list -A\nNAME                    NAMESPACE       REVISION        UPDATED                                 STATUS          CHART                           APP VERSION\ngpu-operator-1753140595 gpu-operator    4               2025-08-14 19:20:42.329819669 -0700 MST deployed        gpu-operator-v25.3.2            v25.3.2    \nkube-prometheus-stack   monitoring      5               2025-08-15 13:06:31.169338089 -0700 MST deployed        kube-prometheus-stack-76.3.\n0    v0.84.1    \n</code></pre>"},{"location":"whitepaper/#gpu-operator-chart-customization","title":"GPU Operator chart customization","text":"<p>The NVIDIA GPU Operator Helm chart deploys a DCGM (Data Center GPU Manager) exporter by default, but there are important nuances:</p> <ul> <li> <p>The DCGM exporter Pod will be created automatically when the operator detects a node with an NVIDIA GPU and the dcgm-exporter component is enabled in its values. </p><pre><code>wsl=&gt; k -n gpu-operator get pods -o wide | grep dcgm\nnvidia-dcgm-exporter-gkg6d                                        1/1     Running     0          56d   10.233.117.209   c2-worker-01.hst.enablement.local   &lt;none&gt;           &lt;none&gt;\nnvidia-dcgm-exporter-r2np6                                        1/1     Running     0          56d   10.233.114.15    c2-worker-02.hst.enablement.local   &lt;none&gt;           &lt;none&gt;\n</code></pre><p></p> </li> <li> <p>In the stock gpu-operator Helm chart from NVIDIA's repository, the DCGM exporter is enabled by default (<code>dcgmExporter.enabled: true</code>), but the ServiceMonitor is disabled by default (<code>serviceMonitor.enabled: false</code>). See the NVIDIA GPU Operator Documentation.</p> </li> </ul> <p></p> <p>You can also verify these default built-in values using the <code>helm show values</code> command.  </p><pre><code>wsl=&gt; helm show values nvidia/gpu-operator | grep -A 15 dcgmExporter\ndcgmExporter:\n  enabled: true\n  repository: nvcr.io/nvidia/k8s\n  image: dcgm-exporter\n  version: 4.3.1-4.4.0-ubuntu22.04\n  imagePullPolicy: IfNotPresent\n  env: []\n  resources: {}\n  service:\n    internalTrafficPolicy: Cluster\n  serviceMonitor:\n    enabled: false\n    interval: 15s\n    honorLabels: false\n    additionalLabels: {}\n    relabelings: []\n</code></pre><p></p> <p>We need to enable  the ServiceMonitor (<code>dcgmExporter.serviceMonitor.enabled: true</code>) in order for Prometheus to automatically scrape the DCGM exporter.</p> <p>The gpu-operator is configured with custom values to enable Prometheus integration. The DCGM exporter runs as a ClusterIP service with ServiceMonitor enabled for automatic metrics discovery by Prometheus. </p><pre><code>wsl=&gt; helm get values gpu-operator-1753140595 -n gpu-operator\nUSER-SUPPLIED VALUES:\ndcgmExporter:\n  service:\n    type: ClusterIP\n  serviceMonitor:\n    enabled: true\n</code></pre><p></p>"},{"location":"whitepaper/#gpu-utilization-simulation","title":"GPU utilization simulation","text":"<p>To simulate GPU load and verify monitoring functionality, we deployed a test pod running the gpu-burn utility. This tool performs intensive GPU computations, allowing us to observe GPU utilization metrics in our monitoring dashboards.</p> <p>The following YAML manifest creates a pod that clones the gpu-burn repository, compiles it, and runs continuous GPU stress testing:</p> <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n    name: gpu-burn\nspec:\n    containers:\n        - name: gpu-burn\n            image: nvidia/cuda:12.2.0-devel-ubuntu22.04 \n            command: [\"/bin/bash\", \"-c\"]\n            args:\n                - |\n                    apt update &amp;&amp; apt install -y git build-essential &amp;&amp; \\\n                    git clone https://github.com/wilicc/gpu-burn.git &amp;&amp; \\\n                    cd gpu-burn &amp;&amp; make &amp;&amp; ./gpu_burn 999999 \n            resources:\n                limits:\n                    nvidia.com/gpu: 1\n    restartPolicy: Never\n</code></pre> <p>Key configuration details: - Base image: <code>nvidia/cuda:12.2.0-devel-ubuntu22.04</code> provides the CUDA development environment - GPU allocation: <code>nvidia.com/gpu: 1</code> requests a single GPU from the cluster - Runtime: <code>gpu_burn 999999</code> runs for approximately 277 hours (effectively continuous) - Restart policy: <code>Never</code> ensures the pod completes its run without automatic restarts  </p> <p>Deploy the pod using: </p><pre><code>kubectl apply -f gpu-burn.yaml\n</code></pre><p></p>"},{"location":"whitepaper/#grafana-cloud-integration","title":"Grafana Cloud Integration","text":"<p>While the local Grafana deployment provides comprehensive monitoring capabilities, organizations often need to share dashboards with team members who cannot directly access the internal infrastructure. Grafana Cloud offers an ideal solution by enabling metrics to be pushed from the local Prometheus instance to a cloud-hosted environment, making dashboards accessible to remote teams without requiring VPN or direct network access.</p>"},{"location":"whitepaper/#prometheus-remote-write","title":"Prometheus Remote Write","text":"<p>Grafana Cloud supports Prometheus remote write protocol, allowing local Prometheus to continuously push metrics to the cloud. This approach offers several advantages:</p> <ul> <li>No inbound firewall rules required - Metrics are pushed outbound from the lab</li> <li>Real-time data synchronization - Metrics appear in Grafana Cloud within seconds</li> <li>Selective metric filtering - Control which metrics are sent to manage costs</li> <li>Multi-cluster aggregation - Consolidate metrics from multiple environments</li> </ul> <p>The integration involves two main steps:</p> <ol> <li>Configure Grafana Cloud credentials - Create a Prometheus remote write endpoint and API key in Grafana Cloud</li> <li>Update Prometheus configuration - Add remote write settings to the kube-prometheus-stack Helm values</li> </ol>"},{"location":"whitepaper/#prometheus-remote-write-diagram","title":"Prometheus Remote Write Diagram","text":"<p>The following diagram from Grafana Cloud documentation shows the architecture of Prometheus remote write. </p> <p></p> <p>How it works: 1. Prometheus scrapes metrics from all targets (DCGM exporter, kube-state-metrics, etc.) 2. Stores metrics locally in TSDB (Time Series Database) 3. Simultaneously pushes metrics to Grafana Cloud via remote write 4. Local Grafana and Prometheus UI can query local data 5. Grafana Cloud receives a copy of all metrics</p>"},{"location":"whitepaper/#configure-grafana-cloud-credentials","title":"Configure Grafana Cloud credentials","text":"<p>Users should log in to <code>grafana.com</code> to access their Grafana stack and retrieve the Prometheus cloud instance API endpoint by selecting \"Details\".</p> <p></p> <p>Select \"Prometheus Details\"</p> <p></p> <p>In the <code>Prometheus Instance Details</code> page, please note \"Remote Write Endpoint\", \"Instance ID\" and generate \"API Token\"</p> <p></p>"},{"location":"whitepaper/#updating-helm-release-with-configured-value","title":"Updating Helm release with configured value","text":"<ol> <li> <p>Create a Kubernetes secret to store the username and password to access the Prometheus cloud instance </p><pre><code>wsl=&gt; GRAFANA_CLOUD_USER=\"&lt;your userid here&gt;\"\nwsl=&gt; GRAFANA_CLOUD_PASSWORD=\"&lt;you token here&gt;\"\n\nwsl=&gt; kubectl create secret generic grafana-cloud-credentials \\\n  --from-literal=username=\"${GRAFANA_CLOUD_USER}\" \\\n  --from-literal=password=\"${GRAFANA_CLOUD_PASSWORD}\" \\\n  -n monitoring\nsecret/grafana-cloud-credentials created\n</code></pre><p></p> </li> <li> <p>Create a Helm custom values YAML file </p><pre><code>wsl=&gt; cat prometheus-remote-write-values.yaml \nprometheus:\n  prometheusSpec:\n    remoteWrite:\n      - url: https://&lt;your-prometheus-id-here&gt;.grafana.net/api/prom/push\n        basicAuth:\n          username:\n            name: grafana-cloud-credentials\n            key: username\n          password:\n            name: grafana-cloud-credentials\n            key: password\n</code></pre><p></p> </li> <li> <p>Upgrade the Helm release </p><pre><code>wsl=&gt; helm upgrade kube-prometheus-stack prometheus-community/kube-prometheus-stack   -n monitoring   -f prometheus-remote-write-values.yaml   --reuse-values\n</code></pre><p></p> </li> </ol>"},{"location":"whitepaper/#proliant-server-nvidia-gpu-utilization-dashboard","title":"Proliant Server Nvidia GPU utilization dashboard","text":"<p>The following screen shows the Grafana Cloud dashboard of HPE Proliant Server Nvidia GPU Utilization.</p> <p></p> <p>The corresponding server GPU utilization from <code>nvidia-smi</code> is shown below. </p><pre><code>wsl=&gt; ssh user01@c2-worker-02.hst.enablement.local nvidia-smi\nMon Oct 20 13:55:11 2025       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 570.133.20             Driver Version: 570.133.20     CUDA Version: 12.8     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA L40S-4C                 On  |   00000000:02:00.0 Off |                    0 |\n| N/A   N/A    P0            N/A  /  N/A  |    3002MiB /   4096MiB |     99%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n\n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|    0   N/A  N/A         3712514      C   ./gpu_burn                             2997MiB |\n+-----------------------------------------------------------------------------------------+\n</code></pre><p></p>"},{"location":"whitepaper/#acknowledgements","title":"Acknowledgements","text":"<p>Special thanks to HPE's Lionel Jullien for his excellent work on HPE GreenLake Compute Ops Management: - How to monitor HPE GreenLake Compute Ops Management infrastructure with Grafana Metrics Dashboards - GitHub repository for HPE GreenLake Compute Ops Management - Postman collection for HPE GreenLake Compute Ops Management RESTful API</p>"}]}